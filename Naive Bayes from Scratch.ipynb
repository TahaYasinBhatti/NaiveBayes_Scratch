{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"golf-dataset.csv\")\n",
    "X,y  = pre_processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of samples of the data are \n",
    "X_size = X.shape[0]\n",
    "\n",
    "# no of features of the data are \n",
    "X_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df):\n",
    "\n",
    " \n",
    "    X = df.drop([df.columns[-1]], axis = 1)\n",
    "    y = df[df.columns[-1]]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = {}\n",
    "likelihoods = {}\n",
    "pred_prob = {}    \n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_class_probs(y,X_size):\n",
    "\n",
    "    for outcome in np.unique(y):\n",
    "        outcome_count = sum(y == outcome)\n",
    "        class_probs[outcome] = outcome_count / X_size\n",
    "        print(\"print class_prob\",class_probs)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print class_prob {'No': 0.3076923076923077}\n",
      "print class_prob {'No': 0.3076923076923077, 'Yes': 0.6923076923076923}\n"
     ]
    }
   ],
   "source": [
    "calc_class_probs(y,X_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_likelihoods(X,y):\n",
    "\n",
    "\n",
    "        features = list(X.columns)\n",
    "        for feature in features:\n",
    "            for outcome in np.unique(y):\n",
    "                outcome_count = sum(y == outcome)\n",
    "                feat_likelihood = X[feature][y[y == outcome].index.values.tolist()].value_counts().to_dict()\n",
    "                for feat_val, count in feat_likelihood.items():\n",
    "                    likelihoods[feature][str(feat_val) + '_' + outcome] = count/outcome_count\n",
    "        print(\"print likelihoods\",likelihoods)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    \n",
    "        features = list(X.columns)\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        train_size = X.shape[0]\n",
    "        num_feats = X.shape[1]\n",
    "\n",
    "        for feature in features:\n",
    "            likelihoods[feature] = {}\n",
    "            pred_prob[feature] = {}\n",
    "\n",
    "            for feature_val in np.unique(X_train[feature]):\n",
    "                pred_prob[feature].update({str (feature_val): 0})\n",
    "\n",
    "                for outcome in np.unique(y_train):\n",
    "                    likelihoods[feature].update({str (feature_val)+'_'+outcome:0})\n",
    "                    class_probs.update({outcome: 0})\n",
    "\n",
    "        calc_class_probs(y_train,train_size)\n",
    "        calc_likelihoods(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print class_prob {'No': 0.4, 'Yes': 0}\n",
      "print class_prob {'No': 0.4, 'Yes': 0.6}\n",
      "print likelihoods {'Outlook': {'Overcast_No': 0, 'Overcast_Yes': 0.3333333333333333, 'Rainy_No': 0.75, 'Rainy_Yes': 0.16666666666666666, 'Sunny_No': 0.25, 'Sunny_Yes': 0.5}, 'Temp': {'Cool_No': 0.25, 'Cool_Yes': 0.5, 'Hot_No': 0.5, 'Hot_Yes': 0, 'Mild_No': 0.25, 'Mild_Yes': 0.5}, 'Humidity': {'High_No': 0.75, 'High_Yes': 0.3333333333333333, 'Normal_No': 0.25, 'Normal_Yes': 0.6666666666666666}, 'Windy': {'False_No': 0.5, 'False_Yes': 0.8333333333333334, 'True_No': 0.5, 'True_Yes': 0.16666666666666666}}\n"
     ]
    }
   ],
   "source": [
    " # first five rows of dataframe\n",
    "X2 = X.iloc[0:10]\n",
    "y2 = y.iloc[0:10]\n",
    "fit(X2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def predict(X_test):\n",
    "\n",
    "        \"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
    "        features = list(X.columns)\n",
    "        results = []\n",
    "        X_test = np.array(X_test)\n",
    "        for i in X_test:\n",
    "            probs_outcome = {}\n",
    "            for b in np.unique(y_train):\n",
    "                probabilty = class_probs[b]\n",
    "                likelihood = 1\n",
    "                evidence = 1\n",
    "\n",
    "                for x, feature_val in zip(features, i):\n",
    "                    likelihood *= likelihoods[x][str(feature_val) + '_' + b]\n",
    "                output_class = (likelihood * probabilty)\n",
    "\n",
    "                probs_outcome[b] = output_class\n",
    "\n",
    "            result = probs_outcome\n",
    "            results.append(result)\n",
    "\n",
    "        return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'No': 0.009375000000000001, 'Yes': 0.008333333333333333}]\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([['Sunny','Mild', 'High', 'True']])\n",
    "probs = predict(X_test)\n",
    "print (probs)\n",
    "if (probs[0][\"No\"] > probs[0][\"Yes\"]):\n",
    "    print(\"No\")\n",
    "elif (probs[0][\"Yes\"] > probs[0][\"No\"]):\n",
    "    print(\"Yes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
